{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['delivery', 'alcohol', 'bike_parking', 'credit_card', 'caters', 'dogs',\n",
       "       'good_for_kids', 'good_for_groups', 'happy_hour', 'tv',\n",
       "       'outdoor_seating', 'price_range', 'reservations', 'table_service',\n",
       "       'take_out', 'wheelchair', 'wifi', 'hours_per_week', 'open_on_weekend',\n",
       "       'food_type_one_American', 'food_type_one_Barbeque',\n",
       "       'food_type_one_Burgers', 'food_type_one_Cafes',\n",
       "       'food_type_one_Cajun/Creole', 'food_type_one_Chicken Wings',\n",
       "       'food_type_one_Chinese', 'food_type_one_Delis', 'food_type_one_Diners',\n",
       "       'food_type_one_Greek', 'food_type_one_Indian', 'food_type_one_Italian',\n",
       "       'food_type_one_Japanese', 'food_type_one_Mexican',\n",
       "       'food_type_one_Sandwiches', 'food_type_one_Seafood',\n",
       "       'food_type_one_Steakhouses', 'food_type_one_Thai',\n",
       "       'food_type_one_Vietnamese', 'food_type_one_None', 'state_encoded',\n",
       "       'delivery_drive_thru'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['delivery', 'alcohol', 'bike_parking', 'credit_card', 'caters', 'dogs',\n",
       "       'good_for_kids', 'good_for_groups', 'happy_hour', 'tv',\n",
       "       'outdoor_seating', 'price_range', 'reservations', 'table_service',\n",
       "       'take_out', 'wheelchair', 'wifi', 'hours_per_week', 'open_on_weekend',\n",
       "       'food_type_one_American', 'food_type_one_Barbeque',\n",
       "       'food_type_one_Burgers', 'food_type_one_Cafes',\n",
       "       'food_type_one_Cajun/Creole', 'food_type_one_Chicken Wings',\n",
       "       'food_type_one_Chinese', 'food_type_one_Delis', 'food_type_one_Diners',\n",
       "       'food_type_one_Greek', 'food_type_one_Indian', 'food_type_one_Italian',\n",
       "       'food_type_one_Japanese', 'food_type_one_Mexican',\n",
       "       'food_type_one_Sandwiches', 'food_type_one_Seafood',\n",
       "       'food_type_one_Steakhouses', 'food_type_one_Thai',\n",
       "       'food_type_one_Vietnamese', 'food_type_one_None', 'state_encoded',\n",
       "       'delivery_drive_thru'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare the data\n",
    "file_path = \"../data/df_restaurants_model.csv\"\n",
    "df_restaurants_model = pd.read_csv(file_path)\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "df_restaurants_model = df_restaurants_model.astype({col: 'int' for col in df_restaurants_model.select_dtypes(include=['bool']).columns})\n",
    "\n",
    "# Feature engineering: create interaction term\n",
    "df_restaurants_model['delivery_drive_thru'] = df_restaurants_model['delivery'] * df_restaurants_model['drive_thru']\n",
    "X = df_restaurants_model.drop(columns=['stars'])\n",
    "\n",
    "# Safely drop columns that may not exist\n",
    "columns_to_drop = ['appointment_only', 'coat_check', 'drive_thru', 'hours_weekend']\n",
    "X_reduced = X.drop(columns=[col for col in columns_to_drop if col in X.columns])\n",
    "\n",
    "y = df_restaurants_model['stars']\n",
    "\n",
    "X_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline for preprocessing\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'learning_rate': [0.05],\n",
    "    'max_depth': [7],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'gamma': [0.1],\n",
    "    'reg_alpha': [0],\n",
    "    'reg_lambda': [10]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "xgb = XGBRegressor(random_state=42, eval_metric='rmse')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=5,  # Increased cross-validation for better robustness\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Use the best model from GridSearchCV directly without saving/loading\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_xgb_model.predict(X_test_processed)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Extract the Booster object from the XGBRegressor model\n",
    "booster = best_xgb_model.get_booster()\n",
    "\n",
    "# Map feature importance to the feature names (convert to a list)\n",
    "booster.feature_names = X_train.columns.tolist()  # Ensure it's a list of feature names\n",
    "\n",
    "# Get the feature importance values\n",
    "importance_dict = booster.get_score(importance_type='weight')\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier handling\n",
    "importance_df = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Importance'])\n",
    "\n",
    "# Sort the DataFrame by importance values in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(importance_df)\n",
    "\n",
    "# Now you can export or use the `importance_df` for building charts\n",
    "# For example, saving it to CSV for use in PowerPoint or other tools\n",
    "importance_df.to_csv(\"feature_importance.csv\", index=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "xgb.plot_importance(booster, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.41499904417815814\n",
      "Results successfully exported to model_performance_and_importance.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Use the best model from GridSearchCV directly without saving/loading\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_xgb_model.predict(X_test_processed)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Extract the Booster object from the XGBRegressor model\n",
    "booster = best_xgb_model.get_booster()\n",
    "\n",
    "# Map feature importance to the feature names (convert to a list)\n",
    "booster.feature_names = X_train.columns.tolist()  # Ensure it's a list of feature names\n",
    "\n",
    "# Get the feature importance values\n",
    "importance_dict = booster.get_score(importance_type='weight')\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier handling\n",
    "importance_df = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Importance'])\n",
    "\n",
    "# Sort the DataFrame by importance values in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Add the R-squared value to a new row at the top of the DataFrame\n",
    "r2_df = pd.DataFrame([['R-squared', r2]], columns=['Feature', 'Importance'])\n",
    "final_df = pd.concat([r2_df, importance_df], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_file = \"model_performance_and_importance.xlsx\"\n",
    "final_df.to_excel(output_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Results successfully exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52263, 41)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.state_encoded.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_pred = np.array([1, 0, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1,\n",
    "       1, 2.0, 1, 1,\n",
    "       1, 1, 1, 0.0570, 1,\n",
    "       1, 0,\n",
    "       0, 0,\n",
    "       0, 0,\n",
    "       0, 0, 0,\n",
    "       0, 0, 0,\n",
    "       0, 0,\n",
    "       0, 0,\n",
    "       0, 0,\n",
    "       0, 0, 13,\n",
    "       1])\n",
    "\n",
    "X_new_pred = X_new_pred.reshape(1, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5151768\n"
     ]
    }
   ],
   "source": [
    "y_pred_new = best_xgb_model.predict(X_new_pred)\n",
    "print(y_pred_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.5151768], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
